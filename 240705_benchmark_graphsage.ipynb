{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import radius_graph  as RadiusGraph\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine formula for distance calculation between two points on the Earth\n",
    "def haversine_dist(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Convert positions to Cartesian coordinates for KD-Tree (optional step for spherical distance)\n",
    "def latlon_to_cartesian(lat, lon):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    lat_rad = np.radians(lat)\n",
    "    lon_rad = np.radians(lon)\n",
    "    x = R * np.cos(lat_rad) * np.cos(lon_rad)\n",
    "    y = R * np.cos(lat_rad) * np.sin(lon_rad)\n",
    "    z = R * np.sin(lat_rad)\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset fuction\n",
    "\n",
    "def create_graph_dataset(embeddings, sll, idx, radius_km=250):\n",
    "\n",
    "    # create train and val embeddings\n",
    "    embeddings = embeddings[idx]\n",
    "\n",
    "    # create train and val metadata\n",
    "    sll = sll.iloc[idx]\n",
    "\n",
    "    positions = []\n",
    "    for i in range(len(sll)):\n",
    "        positions.append([sll.iloc[i][1], sll.iloc[i][2]])\n",
    "    positions = torch.tensor(positions)\n",
    "    \n",
    "    cartesian_positions = np.array([latlon_to_cartesian(lat, lon) for lat, lon in positions])\n",
    "\n",
    "    # Create KD-Tree\n",
    "    kdtree = KDTree(cartesian_positions)\n",
    "\n",
    "    # Use KD-Tree to find all neighbors within the specified radius\n",
    "    print('Finding edges...')\n",
    "    edges = []\n",
    "    for i in range(len(positions)):\n",
    "        indices = kdtree.query_ball_point(cartesian_positions[i], radius_km / 6371)  # Normalized radius for KD-Tree\n",
    "        for j in indices:\n",
    "            if i != j:  # Skip self-loops\n",
    "                edges.append([i, j])\n",
    "\n",
    "    # Convert edges to PyTorch Geometric format\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Calculate edge attributes (inverted distances in km) for the edges\n",
    "    print('Calculating edge attributes...')\n",
    "    edge_attr = torch.tensor([1/(haversine_dist(positions[i][0], positions[i][1], positions[j][0], positions[j][1]) + 1) for i, j in edges], dtype=torch.float)\n",
    "\n",
    "\n",
    "    # Create the PyTorch Geometric Data object\n",
    "    print('Creating Data object...')\n",
    "    data = Data(x=embeddings, edge_index=edge_index, edge_attr=edge_attr, pos=torch.tensor(positions))\n",
    "    print('Data object created.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get labels for a batch (fetching from label_dict)\n",
    "def get_labels(survey_ids):\n",
    "    labels = torch.zeros(len(survey_ids), num_classes)\n",
    "    for i, survey_id in enumerate(survey_ids):\n",
    "        species_ids = label_dict[int(survey_id)]\n",
    "        for species_id in species_ids:\n",
    "            labels[i, species_id] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88987, 2768]) (88987, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load your embeddings and train_metadata\n",
    "embeddings = torch.load('../eda/embeddings.pt')\n",
    "metadata = pd.read_csv('../data/l1/GLC24_PA_metadata_train.csv')\n",
    "sll = metadata.drop_duplicates(subset=['surveyId'])\n",
    "sll = sll[['surveyId', 'lat', 'lon']]\n",
    "\n",
    "print(embeddings.shape, sll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88987\n"
     ]
    }
   ],
   "source": [
    "# Create labels dictionary\n",
    "metadata = metadata.dropna(subset=[\"speciesId\"]).reset_index(drop=True)\n",
    "metadata['speciesId'] = metadata['speciesId'].astype(int)\n",
    "label_dict = metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "\n",
    "# print number of keys in label_dict\n",
    "print(len(label_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score_from_tensors(y_true, y_pred, threshold=0.5):\n",
    "    \n",
    "    y_pred = (y_pred >= threshold)\n",
    "    y_true = y_true.cpu().bool()\n",
    "    y_pred = y_pred.cpu().bool()\n",
    "    \n",
    "    TP = (y_true & y_pred).sum(axis=1)  # True Positives per sample\n",
    "    FP = (y_true & ~y_pred).sum(axis=1)  # False Positives per sample\n",
    "    FN = (~y_true & y_pred).sum(axis=1)  # False Negatives per sample\n",
    "\n",
    "    # compute f1 score for each sample\n",
    "    pre = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    f1 = 2 * pre * rec / (pre + rec)\n",
    "\n",
    "    # Handle division by zero\n",
    "    f1 = np.nan_to_num(f1)\n",
    "\n",
    "    # compute micro-average f1 score\n",
    "    micro_f1 = np.mean(f1)\n",
    "    # Return mean F1 score across all samples\n",
    "    return micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# Create GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.sage1 = SAGEConv(dim_in, dim_h)\n",
    "        self.sage2 = SAGEConv(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.sage1(x.float(), edge_index)  # Ensure float32\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.sage2(h, edge_index)\n",
    "        return h  # Returning logits instead of applying log_softmax\n",
    "\n",
    "    def fit(self, train_loader, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch {epoch + 1}/{epochs}')\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out = self(batch.x.float().to(device), batch.edge_index.to(device))\n",
    "                \n",
    "                indices = batch.input_id.to(device)\n",
    "                survey_ids = [list(label_dict.keys())[index] for index in indices]\n",
    "                labels = get_labels(survey_ids).to(device)\n",
    "\n",
    "                loss = criterion(out[indices], labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, val_loader):\n",
    "        self.eval()\n",
    "        f1s = []\n",
    "\n",
    "        for batch in val_loader:\n",
    "            \n",
    "            out = self(batch.x.float().to(device), batch.edge_index.to(device))\n",
    "\n",
    "            indices = batch.input_id.to(device)\n",
    "            survey_ids = [list(label_dict.keys())[index] for index in indices]\n",
    "            labels = get_labels(survey_ids).to(device)\n",
    "\n",
    "            f1 = calculate_f1_score_from_tensors(labels, out[indices])\n",
    "            f1s.append(f1)\n",
    "\n",
    "        return np.mean(f1s)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/cd3hr9dn1lz7c18kq8r1dq3w0000gn/T/ipykernel_26909/2355753583.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  positions.append([sll.iloc[i][1], sll.iloc[i][2]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/cd3hr9dn1lz7c18kq8r1dq3w0000gn/T/ipykernel_26909/2355753583.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = Data(x=embeddings, edge_index=edge_index, edge_attr=edge_attr, pos=torch.tensor(positions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Data completed. Proceeding with training...\n",
      "Epoch 1/3\n",
      "Epoch 2/3\n",
      "Epoch 3/3\n",
      "Training complete. Proceeding with validation...\n",
      "Validation completed.\n",
      "Iteration:  2\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Data completed. Proceeding with training...\n",
      "Epoch 1/3\n",
      "Epoch 2/3\n",
      "Epoch 3/3\n",
      "Training complete. Proceeding with validation...\n",
      "Validation completed.\n",
      "Iteration:  3\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Data completed. Proceeding with training...\n",
      "Epoch 1/3\n",
      "Epoch 2/3\n",
      "Epoch 3/3\n",
      "Training complete. Proceeding with validation...\n",
      "Validation completed.\n",
      "Iteration:  4\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Data completed. Proceeding with training...\n",
      "Epoch 1/3\n",
      "Epoch 2/3\n",
      "Epoch 3/3\n",
      "Training complete. Proceeding with validation...\n",
      "Validation completed.\n",
      "Iteration:  5\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Finding edges...\n",
      "Calculating edge attributes...\n",
      "Creating Data object...\n",
      "Data object created.\n",
      "Data completed. Proceeding with training...\n",
      "Epoch 1/3\n",
      "Epoch 2/3\n",
      "Epoch 3/3\n",
      "Training complete. Proceeding with validation...\n",
      "Validation completed.\n"
     ]
    }
   ],
   "source": [
    "f1s_graph = []\n",
    "n=5\n",
    "\n",
    "batch_size = 16\n",
    "num_neighbors = [2, 2]  # Number of neighbors for each layer\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "n_train = int(train_ratio * embeddings.size()[0])\n",
    "\n",
    "device = 'mps'\n",
    "\n",
    "# create array from 0 to len(embeddings)\n",
    "\n",
    "idx = np.arange(embeddings.size()[0])\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    print('Iteration: ', i+1)\n",
    "\n",
    "    # shuffle the array\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    # split the array into train and val\n",
    "\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx = idx[n_train:]\n",
    " \n",
    "    # create dataset\n",
    "    train_dataset = create_graph_dataset(embeddings, sll, train_idx)\n",
    "    val_dataset = create_graph_dataset(embeddings, sll, val_idx)\n",
    "\n",
    "    # create loader\n",
    "    train_loader = NeighborLoader(train_dataset, batch_size=batch_size, num_neighbors=num_neighbors, shuffle=True)\n",
    "    val_loader = NeighborLoader(val_dataset, batch_size=batch_size, num_neighbors=num_neighbors, shuffle=False)\n",
    "\n",
    "    print('Data completed. Proceeding with training...')\n",
    "\n",
    "    model = GraphSAGE(dim_in=embeddings.size()[1], dim_h=128, dim_out=num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    model.fit(train_loader, epochs=3)\n",
    "\n",
    "    print('Training complete. Proceeding with validation...')\n",
    "\n",
    "    f1 = model.test(val_loader)\n",
    "    f1s_graph.append(f1)\n",
    "\n",
    "    print('Validation completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores:  [0.0034528377, 0.003853952, 0.00068660255, 0.0029886272, 0.000913459]\n"
     ]
    }
   ],
   "source": [
    "# print the f1 score\n",
    "\n",
    "print('F1 scores: ', f1s_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "results = pd.DataFrame(f1s_graph, columns=['fme_f1'])\n",
    "results.to_csv(f'{timestamp}_graph_benchmark_results_{n}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clef2024-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
